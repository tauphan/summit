
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Example 2 : Understanding the hyper-parameter optimization &#8212; MultiviewPlatform 0 documentation</title>
    <link rel="stylesheet" href="../_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Example 3 : Understanding the statistical iterations" href="example3.html" />
    <link rel="prev" title="Example 1 : First big step with SuMMIT" href="example1.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="example3.html" title="Example 3 : Understanding the statistical iterations"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="example1.html" title="Example 1 : First big step with SuMMIT"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">MultiviewPlatform 0 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" accesskey="U">Multiview Platform Tutorials</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="example-2-understanding-the-hyper-parameter-optimization">
<h1>Example 2 : Understanding the hyper-parameter optimization<a class="headerlink" href="#example-2-understanding-the-hyper-parameter-optimization" title="Permalink to this headline">¶</a></h1>
<p>If you are not familir with hyper-parameter optimization, see <a class="reference external" href="http://baptiste.bauvin.pages.lis-lab.fr/multiview-machine-learning-omis/tutorials/hps_theory.html">Hyper-parameters 101</a></p>
<div class="section" id="hands-on-experience">
<h2>Hands-on experience<a class="headerlink" href="#hands-on-experience" title="Permalink to this headline">¶</a></h2>
<p>In order to understand the process and it’s usefulness, let’s run some configurations and analyze the results.</p>
<p>This example will focus only on some lines of the configuration file :</p>
<ul class="simple">
<li><code class="code yaml docutils literal notranslate"><span class="name tag"><span class="pre">split</span></span><span class="punctuation"><span class="pre">:</span></span></code>, controlling the ration of size between the testing set and the training set,</li>
<li><code class="code yaml docutils literal notranslate"><span class="name tag"><span class="pre">hps_type</span></span><span class="punctuation"><span class="pre">:</span></span></code>, controlling the type of hyper-parameter search,</li>
<li><code class="code yaml docutils literal notranslate"><span class="name tag"><span class="pre">hps_args</span></span><span class="punctuation"><span class="pre">:</span></span></code>, controlling the parameters of the hyper-parameters search method,</li>
<li><code class="code yaml docutils literal notranslate"><span class="name tag"><span class="pre">nb_folds</span></span><span class="punctuation"><span class="pre">:</span></span></code>, controlling the number of folds in the cross-validation process.</li>
</ul>
<div class="section" id="example-2-1-no-hyper-parameter-optimization-impact-of-split-size">
<h3>Example 2.1 : No hyper-parameter optimization, impact of split size<a class="headerlink" href="#example-2-1-no-hyper-parameter-optimization-impact-of-split-size" title="Permalink to this headline">¶</a></h3>
<p>For this example, we only used a subset of the available classifiers in SuMMIT, to reduce the computation time and the complexity of the results.</p>
<p>Each classifier will first be learned on the default hyper-parameters (as in <a class="reference external" href="http://baptiste.bauvin.pages.lis-lab.fr/multiview-machine-learning-omis/tutorials/example1.html">Example 1</a>)</p>
<p>The monoview classifiers that will be used are <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier">Adaboost</a> and a <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html">decision tree</a>,
and the multivew classifier is a late fusion majority vote. In order to use only a subset of the available classifiers,
three lines in the configuration file are useful :</p>
<ul class="simple">
<li><code class="code yaml docutils literal notranslate"><span class="name tag"><span class="pre">type</span></span><span class="punctuation"><span class="pre">:</span></span></code> (<a class="reference external" href="https://gitlab.lis-lab.fr/baptiste.bauvin/multiview-machine-learning-omis/-/tree/master/multiview_platform/examples/config_files/config_example_2_1_1.yml#L45">l45</a>) in which one has to specify which type of algorithms are needed, here we used  <code class="docutils literal notranslate"><span class="pre">type:</span> <span class="pre">[&quot;monoview&quot;,&quot;multiview&quot;]</span></code>,</li>
<li><code class="code yaml docutils literal notranslate"><span class="name tag"><span class="pre">algos_monoview</span></span><span class="punctuation"><span class="pre">:</span></span></code> (<a class="reference external" href="https://gitlab.lis-lab.fr/baptiste.bauvin/multiview-machine-learning-omis/-/tree/master/multiview_platform/examples/config_files/config_example_2_1_1.yml#L45">l47</a>) in which one specifies the names of the monoview algorithms to run, here we used : <code class="code yaml docutils literal notranslate"><span class="name tag"><span class="pre">algos_monoview</span></span><span class="punctuation"><span class="pre">:</span></span> <span class="punctuation indicator"><span class="pre">[</span></span><span class="literal string"><span class="pre">“decision_tree”</span></span><span class="punctuation indicator"><span class="pre">,</span></span> <span class="literal string"><span class="pre">“adaboost”</span></span><span class="punctuation indicator"><span class="pre">,</span></span> <span class="punctuation indicator"><span class="pre">]</span></span></code></li>
<li><code class="code yaml docutils literal notranslate"><span class="name tag"><span class="pre">algos_multiview</span></span><span class="punctuation"><span class="pre">:</span></span></code> (<a class="reference external" href="https://gitlab.lis-lab.fr/baptiste.bauvin/multiview-machine-learning-omis/-/tree/master/multiview_platform/examples/config_files/config_example_2_1_1.yml#L45">l49</a>) is the same but with multiview algorithms, here we used : <code class="code yaml docutils literal notranslate"><span class="name tag"><span class="pre">algos_multiview</span></span><span class="punctuation"><span class="pre">:</span></span> <span class="punctuation indicator"><span class="pre">[</span></span><span class="literal string"><span class="pre">“majority_voting_fusion”</span></span><span class="punctuation indicator"><span class="pre">,</span></span> <span class="punctuation indicator"><span class="pre">]</span></span></code></li>
</ul>
<p>In order for the platform to understand the names, the user has to give the <strong>name of the python module</strong> in which the classifier is implemented in the platform.</p>
<p>In the config file, the default values for Adaboost’s hyper-parameters are :</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">adaboost</span><span class="p">:</span>
  <span class="nt">n_estimators</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">50</span>
  <span class="nt">base_estimator</span><span class="p">:</span> <span class="s">&quot;DecisionTreeClassifier&quot;</span>
</pre></div>
</div>
<p>(see <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier">adaboost’s sklearn’s page</a> for more information)</p>
<p>For the decision tree :</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">decision_tree</span><span class="p">:</span>
  <span class="nt">max_depth</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3</span>
  <span class="nt">criterion</span><span class="p">:</span> <span class="s">&quot;gini&quot;</span>
  <span class="nt">splitter</span><span class="p">:</span> <span class="s">&quot;best&quot;</span>
</pre></div>
</div>
<p>(<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html">sklearn’s decision tree</a>)</p>
<p>And for the late fusion majority vote :</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">majority_voting_fusion</span><span class="p">:</span>
    <span class="nt">classifier_names</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&quot;decision_tree&quot;</span><span class="p p-Indicator">,</span> <span class="p p-Indicator">]</span>
    <span class="nt">classifier_configs</span><span class="p">:</span>
        <span class="nt">decision_tree</span><span class="p">:</span>
            <span class="nt">max_depth</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3</span>
            <span class="nt">criterion</span><span class="p">:</span> <span class="s">&quot;gini&quot;</span>
            <span class="nt">splitter</span><span class="p">:</span> <span class="s">&quot;best&quot;</span>
</pre></div>
</div>
<p>(It will build a vote with one decision tree on each view, with the specified configuration for the decision trees)</p>
<div class="section" id="learning-on-a-few-examples">
<h4>Learning on a few examples<a class="headerlink" href="#learning-on-a-few-examples" title="Permalink to this headline">¶</a></h4>
<p>To run this example run,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">multiview_platform.execute</span> <span class="kn">import</span> <span class="n">execute</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;example 2.1.1&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>The results for accuracy metric are stored in <code class="docutils literal notranslate"><span class="pre">multiview_platform/examples/results/example_2_1_1/doc_summit/</span></code></p>
<html>
<head><meta charset="utf-8" /></head>
<body>
    <div>
        Fake HTML Figure<br>

        Fake HTML Figure<br>

        Fake HTML Figure<br>

        Fake HTML Figure<br>

        Fake HTML Figure<br>

        Fake HTML Figure<br>

        Fake HTML Figure

    </div>
</body>
</html><p>These results were generated learning on 20% of the dataset and testing on 80% (see the <a class="reference external" href="https://gitlab.lis-lab.fr/baptiste.bauvin/multiview-machine-learning-omis/-/tree/master/multiview_platform/examples/config_files/config_example_2_1_1.yml#L37">config file</a>).</p>
</div>
<div class="section" id="id1">
<h4>Learning on more examples<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h4>
<p>Now, if you run :</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">multiview_platform.execute</span> <span class="kn">import</span> <span class="n">execute</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;example 2.1.2&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>You should obtain these scores in <code class="docutils literal notranslate"><span class="pre">multiview_platform/examples/results/example_2_1/doc_summit/</span></code> :</p>
<html>
<head><meta charset="utf-8" /></head>
<body>
    <div>
        Fake HTML Figure<br>

        Fake HTML Figure<br>

        Fake HTML Figure<br>

        Fake HTML Figure<br>

        Fake HTML Figure<br>

        Fake HTML Figure<br>

        Fake HTML Figure

    </div>
</body>
</html><p>Here we learned on 80% of the dataset and tested on 20%, so the line in the  <a class="reference external" href="https://gitlab.lis-lab.fr/baptiste.bauvin/multiview-machine-learning-omis/-/tree/master/multiview_platform/examples/config_files/config_example_2_1_2.yml#L37">config file</a> has become <code class="docutils literal notranslate"><span class="pre">split:</span> <span class="pre">0.2</span></code>.</p>
<p>The difference between these two examples is noticeable as even if, while learning on more examples, the performance of the decision trees and the late fusion improved, the performance of Adaboost did not improve as it was already over-fitting on the small train set.</p>
</div>
<div class="section" id="conclusion">
<h4>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h4>
<p>The split ratio has two consequences :
- Increasing the test set size decreases the information available in the train set size so either it helps to avoid overfitting (Adaboost) or it can hide useful information to the classifier and therefor decrease its performance (decision tree),
- The second consequence is that decreasing test size will increase the benchmark duration as the classifier will have to learn  on more examples, this duration modification is higher if the dataset has high dimensionality and if the algorithm is algorithmically complex.</p>
</div>
</div>
<div class="section" id="example-2-2-usage-of-randomized-hyper-parameter-optimization">
<h3>Example 2.2 : Usage of randomized hyper-parameter optimization :<a class="headerlink" href="#example-2-2-usage-of-randomized-hyper-parameter-optimization" title="Permalink to this headline">¶</a></h3>
<p>In the previous example, we have seen that the split ratio has an impact on the train duration and performance of the algorithms, b the most time-consuming task is optimizing their hyper parameters.</p>
<p>For all the previous examples, the platform used the hyper-parameters values given in the config file.
This is only useful if one knows the optimal combination of hyper-parameter for the given task.</p>
<p>However, most of the time, they are unknown to the user, and then have to be optimized by the platform.</p>
<p>In this example, we will use an randomized search, one of the two hyper-parameter optimization methods implemented in SuMMIT, to do so we will go through five lines of the config file :</p>
<ul class="simple">
<li><code class="code yaml docutils literal notranslate"><span class="name tag"><span class="pre">hps_type</span></span><span class="punctuation"><span class="pre">:</span></span></code>, controlling the type of hyper-parameter search,</li>
<li><code class="code yaml docutils literal notranslate"><span class="name tag"><span class="pre">n_iter</span></span><span class="punctuation"><span class="pre">:</span></span></code>, controlling the number of random draws during the hyper-parameter search,</li>
<li><code class="code yaml docutils literal notranslate"><span class="name tag"><span class="pre">equivalent_draws</span></span><span class="punctuation"><span class="pre">:</span></span></code>, controlling the number fo draws for multiview algorithms,</li>
<li><code class="code yaml docutils literal notranslate"><span class="name tag"><span class="pre">nb_folds</span></span><span class="punctuation"><span class="pre">:</span></span></code>, controlling the number of folds in the cross-validation process,</li>
<li><code class="code yaml docutils literal notranslate"><span class="name tag"><span class="pre">metric_princ</span></span><span class="punctuation"><span class="pre">:</span></span></code>, controlling which metric will be used in the cross-validation.</li>
</ul>
<p>So if you run SuMMIT with :</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">multiview_platform.execute</span> <span class="kn">import</span> <span class="n">execute</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;example 2.2&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>you run SuMMIT with this combination of arguments (<a class="reference external" href="https://gitlab.lis-lab.fr/baptiste.bauvin/multiview-machine-learning-omis/-/tree/master/multiview_platform/examples/config_files/config_example_2_1.yml#L54">l54-65</a>) :</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">metric_princ</span><span class="p">:</span> <span class="s">&#39;accuracy_score&#39;</span>
<span class="nt">nb_folds</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">5</span>
<span class="nt">hps_type</span><span class="p">:</span> <span class="s">&#39;Random&#39;</span>
<span class="nt">hps_args</span><span class="p">:</span>
  <span class="nt">n_iter</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">5</span>
  <span class="nt">equivalent_draws</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">True</span>
</pre></div>
</div>
<p>This means that SuMMIT will use a modded multiview-compatible version of sklearn’s  <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html">RandomisedSearchCV</a>  with 5 draws and 5 folds of cross validation to optimize the hyper-parameters, according to the accuracy.</p>
<p>Moreover, the <code class="code yaml docutils literal notranslate"><span class="name tag"><span class="pre">equivalent_draws</span></span><span class="punctuation"><span class="pre">:</span></span> <span class="literal scalar plain"><span class="pre">True</span></span></code> argument means that the multiview classifiers will be granted <code class="docutils literal notranslate"><span class="pre">n_iter</span></code> x <code class="docutils literal notranslate"><span class="pre">n_views</span></code> draws so, here <img class="math" src="../_images/math/56700ea6c417942e90c154cbe0acd6fb0776a057.png" alt="5 \times 4 = 20"/> draws, to compensate the fact that they have a much more complex problem to solve.</p>
<p>The computing time of this run should be longer than the previous examples (approximately 10 mins). While SuMMIT computes, let’s see the pseudo code of the benchmark, while using the hyper-parameter optimization:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>for each monoview classifier:
    for each view:
        ┌
        |for each draw (here 5):
        |    for each fold (here 5):
        |        learn the classifier on 4 folds and test it on 1
        |    get the mean metric_princ
        |get the best hyper-parameter set
        └
        learn on the whole training set
and
for each multiview classifier:
    ┌
    |for each draw (here 5*4):
    |    for each fold (here 5):
    |        learn the classifier on 4 folds and test it on 1
    |    get the mean metric_princ
    |get the best hyper-parameter set
    └
    learn on the whole training set
</pre></div>
</div>
<p>The instructions inside the brackets are the one that the hyper-parameter
optimization (HPO) adds.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">As the randomized search has independent steps, it profits a lot from multi-threading, however, it is not available at the moment, but is one of our priorities.</p>
</div>
<div class="section" id="the-results">
<h4>The results<a class="headerlink" href="#the-results" title="Permalink to this headline">¶</a></h4>
<p>Here, we used <code class="code yaml docutils literal notranslate"><span class="name tag"><span class="pre">split</span></span><span class="punctuation"><span class="pre">:</span></span> <span class="literal scalar plain"><span class="pre">0.8</span></span></code> and the results are far better than <a class="reference external" href="http://baptiste.bauvin.pages.lis-lab.fr/multiview-machine-learning-omis/tutorials/example2.html#learning-on-more-examples">earlier</a>, as the classifiers are able to fit the task (the multiview classifier improved its accuracy from 0.46 in example 2.1.1 to 0.59).</p>
<html>
<head><meta charset="utf-8" /></head>
<body>
    <div>
        Fake HTML Figure<br>

        Fake HTML Figure<br>

        Fake HTML Figure<br>

        Fake HTML Figure<br>

        Fake HTML Figure<br>

        Fake HTML Figure<br>

        Fake HTML Figure

    </div>
</body>
</html><p>The choice made here is to allow a different amount of draws for mono and multiview classifiers. However, allowing the same number of draws to both is also available by setting :yaml:` equivalent_draws: False`.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The mutliview algorithm used here is late fusion, which means it learns a monoview classifier on each view and then build a naive majority vote. In terms of hyper parameters, the late fusion classifier has to choose one monoview classifier and its HP <strong>for each view</strong>. This is why the <code class="code yaml docutils literal notranslate"><span class="name tag"><span class="pre">equivalent_draws</span></span><span class="punctuation"><span class="pre">:</span></span></code> parameter is implemented, as with only 5 draws, the late fusion classifier is not able to remotely cover its hyper-parameter space, while the monoview algorithms have a much smaller problem to solve.</p>
</div>
</div>
<div class="section" id="id2">
<h4>Conclusion<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h4>
<p>Even if it adds a lot of computing, for most of the tasks, using the HPO is a necessity to be able to get the most of each classifier in terms of performance.</p>
<p>The HPO is a matter of trade-off between classifier performance and computational demand.
For most algorithms the more draws you allow, the closer to ideal the outputted
hyper-parameter (HP) set one will be, however, many draws mean much longer computational time.</p>
<p>Similarly, the number of folds has a great importance in estimating the
performance of a specific HP set, but more folds take also more time, as one has to train more times and on bigger parts of the dataset.</p>
<p>The figure below represents the duration of the execution on a personal computer
with different fold/draws settings :</p>
<html>
<head><meta charset="utf-8" /></head>
<body>
    <div>
        Fake HTML Figure<br>

        Fake HTML Figure<br>

        Fake HTML Figure<br>

        Fake HTML Figure<br>

        Fake HTML Figure<br>

        Fake HTML Figure<br>

        Fake HTML Figure

    </div>
</body>
</html><div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The durations are for reference only as they highly depend on the hardware.</p>
</div>
</div>
</div>
<div class="section" id="example-2-3-usage-of-grid-search">
<h3>Example 2.3 : Usage of grid search :<a class="headerlink" href="#example-2-3-usage-of-grid-search" title="Permalink to this headline">¶</a></h3>
<p>In SuMMIT, it is possible to use a grid search if one has several possible
hyper-parameter values in mind to test.</p>
<p>In order to set up the grid search one has to provide in the <code class="code yaml docutils literal notranslate"><span class="name tag"><span class="pre">hps_args</span></span><span class="punctuation"><span class="pre">:</span></span></code>
argument the names, parameters and values to test. If one wants to try
several depths for a decision tree, and several <code class="code yaml docutils literal notranslate"><span class="literal scalar plain"><span class="pre">n_estimators</span></span></code> values for Adaboost,</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">hps_type</span><span class="p">:</span> <span class="s">&quot;Grid&quot;</span>
<span class="nt">hps_args</span><span class="p">:</span>
  <span class="nt">decision_tree</span><span class="p">:</span>
    <span class="nt">max_depth</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">1</span><span class="p p-Indicator">,</span><span class="nv">2</span><span class="p p-Indicator">,</span><span class="nv">3</span><span class="p p-Indicator">,</span><span class="nv">4</span><span class="p p-Indicator">,</span><span class="nv">5</span><span class="p p-Indicator">]</span>
  <span class="nt">adaboost</span><span class="p">:</span>
    <span class="nt">n_estimators</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">10</span><span class="p p-Indicator">,</span><span class="nv">15</span><span class="p p-Indicator">,</span><span class="nv">20</span><span class="p p-Indicator">,</span><span class="nv">25</span><span class="p p-Indicator">]</span>
</pre></div>
</div>
<p>Moreover, for the multiview algorithms, we would like to try two configurations for the late fusion classifier :</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">weighted_linear_late_fusion</span><span class="p">:</span>
  <span class="nt">classifiers_names</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="p p-Indicator">[</span><span class="s">&quot;decision_tree&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;decision_tree&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;decision_tree&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;decision_tree&quot;</span><span class="p p-Indicator">]</span>
    <span class="p p-Indicator">-</span> <span class="p p-Indicator">[</span><span class="s">&quot;adaboost&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;adaboost&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;adaboost&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;adaboost&quot;</span><span class="p p-Indicator">,]</span>

  <span class="nt">classifier_configs</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">decision_tree</span><span class="p">:</span>
        <span class="nt">max_depth</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3</span>
      <span class="nt">adaboost</span><span class="p">:</span>
        <span class="nt">n_estimators</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
</pre></div>
</div>
<p>This will try to run the late fusion classifier with either</p>
<ul class="simple">
<li>one decision tree per view, with a maximum depth of 3,</li>
<li>one Adaboost per view with 10 base estimators.</li>
</ul>
</div>
<div class="section" id="hyper-parameter-report">
<h3>Hyper-parameter report<a class="headerlink" href="#hyper-parameter-report" title="Permalink to this headline">¶</a></h3>
<p>The hyper-parameter optimization process generates a report for each
classifier, providing each set of parameters and its cross-validation score,
to be able to extract the relevant parameters for a future benchmark on the
same dataset.</p>
<p>For most of the algorithms, it is possible to paste the report in the config fie,
for example for the decision tree on the first view the <code class="docutils literal notranslate"><span class="pre">*-hps_report.txt</span></code> file generated by the randomized search of <a class="reference external" href="http://baptiste.bauvin.pages.lis-lab.fr/multiview-machine-learning-omis/tutorials/example2.html#example-2-2-usage-of-randomized-hyper-parameter-optimization">example 2.2</a> looks like :</p>
<pre class="literal-block">

criterion: gini
max_depth: 202
splitter: random

                0.28787878787878785
criterion: gini
max_depth: 217
splitter: best

                0.23939393939393935
criterion: entropy
max_depth: 292
splitter: random

                0.21818181818181817
criterion: entropy
max_depth: 275
splitter: best

                0.20454545454545453
criterion: entropy
max_depth: 182
splitter: best

                0.20454545454545453
</pre>
<p>Meaning that the cross validation score of the decision tree on the first view when using the following hyper-parameters is 0.2879.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">criterion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">gini</span>
<span class="nt">max_depth</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">202</span>
<span class="nt">splitter</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">random</span>
</pre></div>
</div>
<p>So to run a decision tree with these exact parameters, one just has to follow the method of <a class="reference external" href="http://baptiste.bauvin.pages.lis-lab.fr/multiview-machine-learning-omis/tutorials/example2.html#example-2-1-no-hyper-parameter-optimization-impact-of-split-size">example 2.1</a> and run SuMMIT with the following hyper-parameter configuration :</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">hps_type</span><span class="p">:</span> <span class="s">&quot;None&quot;</span>
<span class="nt">hps_args</span><span class="p">:</span>
    <span class="nt">decision_tree</span><span class="p">:</span>
        <span class="nt">criterion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">gini</span>
        <span class="nt">max_depth</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">202</span>
        <span class="nt">splitter</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">random</span>
</pre></div>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Example 2 : Understanding the hyper-parameter optimization</a><ul>
<li><a class="reference internal" href="#hands-on-experience">Hands-on experience</a><ul>
<li><a class="reference internal" href="#example-2-1-no-hyper-parameter-optimization-impact-of-split-size">Example 2.1 : No hyper-parameter optimization, impact of split size</a><ul>
<li><a class="reference internal" href="#learning-on-a-few-examples">Learning on a few examples</a></li>
<li><a class="reference internal" href="#id1">Learning on more examples</a></li>
<li><a class="reference internal" href="#conclusion">Conclusion</a></li>
</ul>
</li>
<li><a class="reference internal" href="#example-2-2-usage-of-randomized-hyper-parameter-optimization">Example 2.2 : Usage of randomized hyper-parameter optimization :</a><ul>
<li><a class="reference internal" href="#the-results">The results</a></li>
<li><a class="reference internal" href="#id2">Conclusion</a></li>
</ul>
</li>
<li><a class="reference internal" href="#example-2-3-usage-of-grid-search">Example 2.3 : Usage of grid search :</a></li>
<li><a class="reference internal" href="#hyper-parameter-report">Hyper-parameter report</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="example1.html"
                        title="previous chapter">Example 1 : First big step with SuMMIT</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="example3.html"
                        title="next chapter">Example 3 : Understanding the statistical iterations</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/tutorials/example2.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="example3.html" title="Example 3 : Understanding the statistical iterations"
             >next</a> |</li>
        <li class="right" >
          <a href="example1.html" title="Example 1 : First big step with SuMMIT"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">MultiviewPlatform 0 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" >Multiview Platform Tutorials</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2019, Baptiste BAUVIN.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.8.3.
    </div>
  </body>
</html>