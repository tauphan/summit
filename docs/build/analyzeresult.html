
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Result analysis module &#8212; MultiviewPlatform 0 documentation</title>
    <link rel="stylesheet" href="_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">MultiviewPlatform 0 documentation</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="module-multiview_platform.mono_multi_view_classifiers.result_analysis">
<span id="result-analysis-module"></span><h1>Result analysis module<a class="headerlink" href="#module-multiview_platform.mono_multi_view_classifiers.result_analysis" title="Permalink to this headline">¶</a></h1>
<dl class="function">
<dt id="multiview_platform.mono_multi_view_classifiers.result_analysis.analyzeMulticlass">
<code class="descname">analyzeMulticlass</code><span class="sig-paren">(</span><em>results</em>, <em>stats_iter</em>, <em>benchmark_argument_dictionaries</em>, <em>nb_examples</em>, <em>nb_labels</em>, <em>multiclass_labels</em>, <em>metrics</em>, <em>classification_indices</em>, <em>directories</em>, <em>example_ids</em><span class="sig-paren">)</span><a class="headerlink" href="#multiview_platform.mono_multi_view_classifiers.result_analysis.analyzeMulticlass" title="Permalink to this definition">¶</a></dt>
<dd><p>Used to transform one versus one results in multiclass results and to publish it</p>
</dd></dl>

<dl class="function">
<dt id="multiview_platform.mono_multi_view_classifiers.result_analysis.analyze_biclass">
<code class="descname">analyze_biclass</code><span class="sig-paren">(</span><em>results</em>, <em>benchmark_argument_dictionaries</em>, <em>stats_iter</em>, <em>metrics</em>, <em>example_ids</em><span class="sig-paren">)</span><a class="headerlink" href="#multiview_platform.mono_multi_view_classifiers.result_analysis.analyze_biclass" title="Permalink to this definition">¶</a></dt>
<dd><p>Used to extract and format the results of the different biclass experimentations performed.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>results</strong> (<em>list</em>) – The result list returned by the bencmark execution function. For each executed benchmark, contains
a flag &amp; a result element.
The flag is a way to identify to which benchmark the results belong, formatted this way :
<cite>flag = iter_index, [classifierPositive, classifierNegative]</cite> with
- <cite>iter_index</cite> the index of the statistical iteration
- <cite>[classifierPositive, classifierNegative]</cite> the indices of the labels considered positive and negative
by the classifier (mainly useful for one versus one multiclass classification).</li>
<li><strong>benchmark_argument_dictionaries</strong> (<em>list of dicts</em>) – The list of all the arguments passed to the benchmark executing functions.</li>
<li><strong>statsIter</strong> (<em>int</em>) – The number of statistical iterations.</li>
<li><strong>metrics</strong> (<em>list of lists</em>) – THe list containing the metrics and their configuration.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>biclassResults</strong> – The list contains a dictionary for each statistical iteration. This dictionary contains a dictionary for each
label combination, regrouping the scores for each metrics and the information useful to plot errors on examples.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">list of dicts of dicts</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="multiview_platform.mono_multi_view_classifiers.result_analysis.analyze_iter_multiclass">
<code class="descname">analyze_iter_multiclass</code><span class="sig-paren">(</span><em>multiclass_results</em>, <em>directory</em>, <em>stats_iter</em>, <em>metrics</em>, <em>data_base_name</em>, <em>nb_examples</em>, <em>example_ids</em><span class="sig-paren">)</span><a class="headerlink" href="#multiview_platform.mono_multi_view_classifiers.result_analysis.analyze_iter_multiclass" title="Permalink to this definition">¶</a></dt>
<dd><p>Used to mean the multiclass results on the iterations executed with different random states</p>
</dd></dl>

<dl class="function">
<dt id="multiview_platform.mono_multi_view_classifiers.result_analysis.analyzebiclass_iter">
<code class="descname">analyzebiclass_iter</code><span class="sig-paren">(</span><em>biclass_results</em>, <em>stats_iter</em>, <em>directory</em>, <em>labels_dictionary</em>, <em>data_base_name</em>, <em>example_ids</em><span class="sig-paren">)</span><a class="headerlink" href="#multiview_platform.mono_multi_view_classifiers.result_analysis.analyzebiclass_iter" title="Permalink to this definition">¶</a></dt>
<dd><p>Used to format the results in order to plot the mean results on the iterations</p>
</dd></dl>

<dl class="function">
<dt id="multiview_platform.mono_multi_view_classifiers.result_analysis.autolabel">
<code class="descname">autolabel</code><span class="sig-paren">(</span><em>rects</em>, <em>ax</em>, <em>set=1</em>, <em>std=None</em><span class="sig-paren">)</span><a class="headerlink" href="#multiview_platform.mono_multi_view_classifiers.result_analysis.autolabel" title="Permalink to this definition">¶</a></dt>
<dd><p>Used to print the score below the bars.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>rects</strong> (<em>pyplot bar object</em>) – THe bars.</li>
<li><strong>ax</strong> (<em>pyplot ax object</em>) – The ax.</li>
<li><strong>set</strong> (<em>integer</em>) – 1 means the test scores, anything else means the train score</li>
<li><strong>std</strong> (<em>None</em><em> or </em><em>array</em>) – The standard deviations in the case of statsIter results.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="multiview_platform.mono_multi_view_classifiers.result_analysis.format_previous_results">
<code class="descname">format_previous_results</code><span class="sig-paren">(</span><em>biclass_results</em><span class="sig-paren">)</span><a class="headerlink" href="#multiview_platform.mono_multi_view_classifiers.result_analysis.format_previous_results" title="Permalink to this definition">¶</a></dt>
<dd><p>Formats each statistical iteration’s result into a mean/std analysis for
the metrics and adds the errors of each statistical iteration.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>biclass_results</strong> (<em>The raw results</em><em>, </em><em>for each statistical iteration i contains</em>) – <ul class="simple">
<li>biclass_results[i][“metrics_scores”] is a dictionary with a pd.dataframe
for each metrics</li>
<li>biclass_results[i][“example_errors”], a dicaitonary with a np.array</li>
</ul>
<p>for each classifier.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><strong>metrics_analysis</strong> (<em>The mean and std dataframes for each metrics</em>)</li>
<li><strong>error_analysis</strong> (<em>A dictionary containing the added errors</em>) – arrays for each classifier</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="multiview_platform.mono_multi_view_classifiers.result_analysis.gen_error_data">
<code class="descname">gen_error_data</code><span class="sig-paren">(</span><em>example_errors</em><span class="sig-paren">)</span><a class="headerlink" href="#multiview_platform.mono_multi_view_classifiers.result_analysis.gen_error_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Used to format the error data in order to plot it efficiently. The data is saves in a <cite>.csv</cite> file.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>example_errors</strong> (<em>dict of dicts of np.arrays</em>) – A dictionary conatining all the useful data. Organized as :
<cite>example_errors[&lt;classifier_name&gt;][“error_on_examples”]</cite> is a np.array of ints with a
- 1 if the classifier <cite>&lt;classifier_name&gt;</cite> classifier well the example,
- 0 if it fail to classify the example,
- -100 if it did not classify the example (multiclass one versus one).</li>
<li><strong>base_file_name</strong> (<em>list of str</em>) – The name of the file in which the figure will be saved (“2D_plot_data.csv” and “bar_plot_data.csv” will
be added at the end).</li>
<li><strong>nbCopies</strong> (<em>int</em><em>, </em><em>optinal</em><em>, </em><em>default: 2</em>) – The number of times the data is copied (classifier wise) in order for the figure to be more readable.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>nbClassifiers</strong> (<em>int</em>) – Number of different classifiers.</li>
<li><strong>nbExamples</strong> (<em>int</em>) – NUmber of examples.</li>
<li><strong>nbCopies</strong> (<em>int</em>) – The number of times the data is copied (classifier wise) in order for the figure to be more readable.</li>
<li><strong>classifiers_names</strong> (<em>list of strs</em>) – The names fo the classifiers.</li>
<li><strong>data</strong> (np.array of shape <cite>(nbClassifiers, nbExamples)</cite>) – A matrix with zeros where the classifier failed to classifiy the example, ones where it classified it well
and -100 if the example was not classified.</li>
<li><strong>error_on_examples</strong> (np.array of shape <cite>(nbExamples,)</cite>) – An array counting how many classifiers failed to classifiy each examples.</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="multiview_platform.mono_multi_view_classifiers.result_analysis.gen_metrics_scores_multiclass">
<code class="descname">gen_metrics_scores_multiclass</code><span class="sig-paren">(</span><em>results</em>, <em>true_labels</em>, <em>metrics</em>, <em>arguments_dictionaries</em><span class="sig-paren">)</span><a class="headerlink" href="#multiview_platform.mono_multi_view_classifiers.result_analysis.gen_metrics_scores_multiclass" title="Permalink to this definition">¶</a></dt>
<dd><p>Used to add all the metrics scores to the multiclass result structure  for each clf and each iteration</p>
</dd></dl>

<dl class="function">
<dt id="multiview_platform.mono_multi_view_classifiers.result_analysis.get_arguments">
<code class="descname">get_arguments</code><span class="sig-paren">(</span><em>benchmark_argument_dictionaries</em>, <em>flag</em><span class="sig-paren">)</span><a class="headerlink" href="#multiview_platform.mono_multi_view_classifiers.result_analysis.get_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Used to get the arguments passed to the benchmark executing function corresponding to the flag of a
biclass experimentation.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>flag</strong> (<em>list</em>) – The needed experimentation’s flag.</li>
<li><strong>benchmark_argument_dictionaries</strong> (<em>list of dicts</em>) – The list of all the arguments passed to the benchmark executing functions.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>benchmarkArgumentDictionary</strong> – All the arguments passed to the benchmark executing function for the needed experimentation.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">dict</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="multiview_platform.mono_multi_view_classifiers.result_analysis.get_error_on_labels_multiclass">
<code class="descname">get_error_on_labels_multiclass</code><span class="sig-paren">(</span><em>multiclass_results</em>, <em>multiclass_labels</em><span class="sig-paren">)</span><a class="headerlink" href="#multiview_platform.mono_multi_view_classifiers.result_analysis.get_error_on_labels_multiclass" title="Permalink to this definition">¶</a></dt>
<dd><p>Used to add all the arrays showing on which example there is an error for each clf and each iteration</p>
</dd></dl>

<dl class="function">
<dt id="multiview_platform.mono_multi_view_classifiers.result_analysis.get_example_errors_biclass">
<code class="descname">get_example_errors_biclass</code><span class="sig-paren">(</span><em>groud_truth</em>, <em>results</em><span class="sig-paren">)</span><a class="headerlink" href="#multiview_platform.mono_multi_view_classifiers.result_analysis.get_example_errors_biclass" title="Permalink to this definition">¶</a></dt>
<dd><p>Used to get for each classifier and each example whether the classifier has misclassified the example or not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>ground_truth</strong> (<em>numpy array of 0</em><em>, </em><em>1 and -100</em><em> (</em><em>if multiclass</em><em>)</em>) – The array with the real labels of the examples</li>
<li><strong>results</strong> (<em>list of MonoviewResult and MultiviewResults objects</em>) – A list containing all the resluts for all the mono- &amp; multi-view experimentations.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>example_errors</strong> – For each classifier, has an entry with a <cite>np.array</cite> over the examples, with a 1 if the examples was
well-classified, a 0 if not and if it’s multiclass classification, a -100 if the examples was not seen during
the one versus one classification.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">dict of np.array</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="multiview_platform.mono_multi_view_classifiers.result_analysis.get_feature_importances">
<code class="descname">get_feature_importances</code><span class="sig-paren">(</span><em>result</em>, <em>feature_names=None</em><span class="sig-paren">)</span><a class="headerlink" href="#multiview_platform.mono_multi_view_classifiers.result_analysis.get_feature_importances" title="Permalink to this definition">¶</a></dt>
<dd><p>Extracts the feature importance from the monoview results and stores them in a dictionnary :
feature_importance[view_name] is a pandas.DataFrame of size n_feature*n_clf
containing a score of importance for each feature.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>result</strong> (<em>list of results</em>) – </td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>feature_importances</strong> – The dictionary containing all the feature importance for each view as pandas DataFrames</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">dict of pd.DataFrame</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="multiview_platform.mono_multi_view_classifiers.result_analysis.get_fig_size">
<code class="descname">get_fig_size</code><span class="sig-paren">(</span><em>nb_results</em>, <em>min_size=15</em>, <em>multiplier=1.0</em>, <em>bar_width=0.35</em><span class="sig-paren">)</span><a class="headerlink" href="#multiview_platform.mono_multi_view_classifiers.result_analysis.get_fig_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Used to get the image size to save the figure and the bar width, depending on the number of scores to plot.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>nb_results</strong> (<em>int</em>) – The number of couple of bar to plot.</li>
<li><strong>min_size</strong> (<em>int</em>) – The minimum size of the image, if there are few classifiers to plot.</li>
<li><strong>multiplier</strong> (<em>float</em>) – The ratio between the image size and the number of classifiers.</li>
<li><strong>bar_width</strong> (<em>float</em>) – The width of the bars in the figure. Mainly here to centralize bar_width.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>fig_kwargs</strong> (<em>dict of arguments</em>) – The argument restraining the size of the figure, usable directly in the <cite>subplots</cite> function of
<cite>matplotlib.pyplot</cite>.</li>
<li><strong>bar_width</strong> (<em>float</em>) – The width of the bars in the figure. Mainly here to centralize bar_width.</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="multiview_platform.mono_multi_view_classifiers.result_analysis.get_metrics_scores_biclass">
<code class="descname">get_metrics_scores_biclass</code><span class="sig-paren">(</span><em>metrics</em>, <em>results</em><span class="sig-paren">)</span><a class="headerlink" href="#multiview_platform.mono_multi_view_classifiers.result_analysis.get_metrics_scores_biclass" title="Permalink to this definition">¶</a></dt>
<dd><p>Used to extract metrics scores in case of biclass classification</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>metrics</strong> (<em>list of lists</em>) – The metrics names with configuration metrics[i][0] = name of metric i</li>
<li><strong>results</strong> (<em>list of MonoviewResult and MultiviewResults objects</em>) – A list containing all the results for all the monoview experimentations.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>metricsScores</strong> – Regroups all the scores for each metrics for each classifier and for the train and test sets.
organized as :
-<cite>metricScores[metric_name][“classifiers_names”]</cite> is a list of all the classifiers available for this metric,
-<cite>metricScores[metric_name][“train_scores”]</cite> is a list of all the available classifiers scores on the train set,
-<cite>metricScores[metric_name][“test_scores”]</cite> is a list of all the available classifiers scores on the test set.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">dict of dict of list</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="multiview_platform.mono_multi_view_classifiers.result_analysis.get_results">
<code class="descname">get_results</code><span class="sig-paren">(</span><em>results</em>, <em>stats_iter</em>, <em>nb_multiclass</em>, <em>benchmark_argument_dictionaries</em>, <em>multiclass_labels</em>, <em>metrics</em>, <em>classification_indices</em>, <em>directories</em>, <em>directory</em>, <em>labels_dictionary</em>, <em>nb_examples</em>, <em>nb_labels</em>, <em>example_ids</em><span class="sig-paren">)</span><a class="headerlink" href="#multiview_platform.mono_multi_view_classifiers.result_analysis.get_results" title="Permalink to this definition">¶</a></dt>
<dd><p>Used to analyze the results of the previous benchmarks</p>
</dd></dl>

<dl class="function">
<dt id="multiview_platform.mono_multi_view_classifiers.result_analysis.iterCmap">
<code class="descname">iterCmap</code><span class="sig-paren">(</span><em>statsIter</em><span class="sig-paren">)</span><a class="headerlink" href="#multiview_platform.mono_multi_view_classifiers.result_analysis.iterCmap" title="Permalink to this definition">¶</a></dt>
<dd><p>Used to generate a colormap that will have a tick for each iteration : the whiter the better.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>statsIter</strong> (<em>int</em>) – The number of statistical iterations.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><strong>cmap</strong> (<em>matplotlib.colors.ListedColorMap object</em>) – The colormap.</li>
<li><strong>norm</strong> (<em>matplotlib.colors.BoundaryNorm object</em>) – The bounds for the colormap.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="multiview_platform.mono_multi_view_classifiers.result_analysis.plot_2d">
<code class="descname">plot_2d</code><span class="sig-paren">(</span><em>data</em>, <em>classifiers_names</em>, <em>nbClassifiers</em>, <em>nbExamples</em>, <em>fileName</em>, <em>minSize=10</em>, <em>width_denominator=2.0</em>, <em>height_denominator=20.0</em>, <em>stats_iter=1</em>, <em>use_plotly=True</em>, <em>example_ids=None</em><span class="sig-paren">)</span><a class="headerlink" href="#multiview_platform.mono_multi_view_classifiers.result_analysis.plot_2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Used to generate a 2D plot of the errors.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>data</strong> (np.array of shape <cite>(nbClassifiers, nbExamples)</cite>) – A matrix with zeros where the classifier failed to classifiy the example, ones where it classified it well
and -100 if the example was not classified.</li>
<li><strong>classifiers_names</strong> (<em>list of str</em>) – The names of the classifiers.</li>
<li><strong>nbClassifiers</strong> (<em>int</em>) – The number of classifiers.</li>
<li><strong>nbExamples</strong> (<em>int</em>) – The number of examples.</li>
<li><strong>nbCopies</strong> (<em>int</em>) – The number of times the data is copied (classifier wise) in order for the figure to be more readable</li>
<li><strong>fileName</strong> (<em>str</em>) – The name of the file in which the figure will be saved (“error_analysis_2D.png” will be added at the end)</li>
<li><strong>minSize</strong> (<em>int</em><em>, </em><em>optinal</em><em>, </em><em>default: 10</em>) – The minimum width and height of the figure.</li>
<li><strong>width_denominator</strong> (<em>float</em><em>, </em><em>optional</em><em>, </em><em>default: 1.0</em>) – To obtain the image width, the number of classifiers will be divided by this number.</li>
<li><strong>height_denominator</strong> (<em>float</em><em>, </em><em>optional</em><em>, </em><em>default: 1.0</em>) – To obtain the image width, the number of examples will be divided by this number.</li>
<li><strong>stats_iter</strong> (<em>int</em><em>, </em><em>optional</em><em>, </em><em>default: 1</em>) – The number of statistical iterations realized.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="multiview_platform.mono_multi_view_classifiers.result_analysis.plot_errors_bar">
<code class="descname">plot_errors_bar</code><span class="sig-paren">(</span><em>error_on_examples</em>, <em>nbClassifiers</em>, <em>nbExamples</em>, <em>fileName</em><span class="sig-paren">)</span><a class="headerlink" href="#multiview_platform.mono_multi_view_classifiers.result_analysis.plot_errors_bar" title="Permalink to this definition">¶</a></dt>
<dd><p>Used to generate a barplot of the muber of classifiers that failed to classify each examples</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>error_on_examples</strong> (np.array of shape <cite>(nbExamples,)</cite>) – An array counting how many classifiers failed to classifiy each examples.</li>
<li><strong>classifiers_names</strong> (<em>list of str</em>) – The names of the classifiers.</li>
<li><strong>nbClassifiers</strong> (<em>int</em>) – The number of classifiers.</li>
<li><strong>nbExamples</strong> (<em>int</em>) – The number of examples.</li>
<li><strong>fileName</strong> (<em>str</em>) – The name of the file in which the figure will be saved (“error_analysis_2D.png” will be added at the end)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="multiview_platform.mono_multi_view_classifiers.result_analysis.plot_metric_scores">
<code class="descname">plot_metric_scores</code><span class="sig-paren">(</span><em>train_scores</em>, <em>test_scores</em>, <em>names</em>, <em>nb_results</em>, <em>metric_name</em>, <em>file_name</em>, <em>tag=''</em>, <em>train_STDs=None</em>, <em>test_STDs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#multiview_platform.mono_multi_view_classifiers.result_analysis.plot_metric_scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Used to plot and save the score barplot for a specific metric.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>train_scores</strong> (<em>list</em><em> or </em><em>np.array of floats</em>) – The scores of each classifier on the training set.</li>
<li><strong>test_scores</strong> (<em>list</em><em> or </em><em>np.array of floats</em>) – The scores of each classifier on the testing set.</li>
<li><strong>names</strong> (<em>list</em><em> or </em><em>np.array of strs</em>) – The names of all the classifiers.</li>
<li><strong>nb_results</strong> (<em>int</em>) – The number of classifiers to plot.</li>
<li><strong>metric_name</strong> (<em>str</em>) – The plotted metric’s name</li>
<li><strong>file_name</strong> (<em>str</em>) – The name of the file where the figure will be saved.</li>
<li><strong>tag</strong> (<em>str</em>) – Some text to personalize the title, must start with a whitespace.</li>
<li><strong>train_STDs</strong> (<em>np.array of floats</em><em> or </em><em>None</em>) – The array containing the standard deviations for the averaged scores on the training set.</li>
<li><strong>test_STDs</strong> (<em>np.array of floats</em><em> or </em><em>None</em>) – The array containing the standard deviations for the averaged scores on the testing set.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="multiview_platform.mono_multi_view_classifiers.result_analysis.publishMetricsGraphs">
<code class="descname">publishMetricsGraphs</code><span class="sig-paren">(</span><em>metrics_scores</em>, <em>directory</em>, <em>database_name</em>, <em>labels_names</em><span class="sig-paren">)</span><a class="headerlink" href="#multiview_platform.mono_multi_view_classifiers.result_analysis.publishMetricsGraphs" title="Permalink to this definition">¶</a></dt>
<dd><p>Used to sort the results (names and both scores) in descending test score order.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>metrics_scores</strong> (<em>dict of dicts of lists</em><em> or </em><em>np.arrays</em>) – Keys : The names of the metrics.
Values : The scores and names of each classifier .</li>
<li><strong>directory</strong> (<em>str</em>) – The path to the directory where the figures will be saved.</li>
<li><strong>database_name</strong> (<em>str</em>) – The name of the database on which the experiments where conducted.</li>
<li><strong>labels_names</strong> (<em>list of strs</em>) – The name corresponding to each numerical label.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">results</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="multiview_platform.mono_multi_view_classifiers.result_analysis.sort_by_test_score">
<code class="descname">sort_by_test_score</code><span class="sig-paren">(</span><em>train_scores</em>, <em>test_scores</em>, <em>names</em>, <em>train_STDs=None</em>, <em>test_STDs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#multiview_platform.mono_multi_view_classifiers.result_analysis.sort_by_test_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Used to sort the results (names and both scores) in descending test score order.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>train_scores</strong> (<em>np.array of floats</em>) – The scores of each classifier on the training set.</li>
<li><strong>test_scores</strong> (<em>np.array of floats</em>) – The scores of each classifier on the testing set.</li>
<li><strong>names</strong> (<em>np.array of strs</em>) – The names of all the classifiers.</li>
<li><strong>train_STDs</strong> (<em>np.array of floats</em><em> or </em><em>None</em>) – The array containing the standard deviations for the averaged scores on the training set.</li>
<li><strong>test_STDs</strong> (<em>np.array of floats</em><em> or </em><em>None</em>) – The array containing the standard deviations for the averaged scores on the testing set.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>sorted_names</strong> (<em>np.array of strs</em>) – The names of all the classifiers, sorted in descending test score order.</li>
<li><strong>sorted_train_scores</strong> (<em>np.array of floats</em>) – The scores of each classifier on the training set, sorted in descending test score order.</li>
<li><strong>sorted_test_scores</strong> (<em>np.array of floats</em>) – The scores of each classifier on the testing set, sorted in descending test score order.</li>
<li><strong>sorted_train_STDs</strong> (<em>np.array of floats or None</em>) – The array containing the standard deviations for the averaged scores on the training set,
sorted in descending test score order.</li>
<li><strong>sorted_test_STDs</strong> (<em>np.array of floats or None</em>) – The array containing the standard deviations for the averaged scores on the testing set,
sorted in descending test score order.</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/analyzeresult.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">MultiviewPlatform 0 documentation</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2019, Baptiste BAUVIN.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.8.3.
    </div>
  </body>
</html>