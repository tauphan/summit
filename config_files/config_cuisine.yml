# The base configuration of the benchmark
log: True
name: ["demo"]
label: "_1_3"
file_type: ".hdf5"
views:
pathf: "/home/baptiste/Documents/Datasets/Generated/"
nice: 0
random_state: 42
nb_cores: 1
full: False
debug: True
add_noise: False
noise_std: 0.0
res_dir: "../results/"
track_tracebacks: False

# All the classification-realted configuration options
multiclass_method: "oneVersusOne"
split: 0.75
nb_folds: 5
nb_class: 2
classes: ['label_1', 'label_3']
type: ["multiview", "monoview"]
algos_monoview: ["cb_boost",]
algos_multiview: ["multiview_cbound_boosting"]
stats_iter: 5
metrics:
  accuracy_score: {}
  f1_score:
    average: 'binary'
metric_princ: "accuracy_score"
hps_type: "None"
hps_args: {}

cb_boost:
  n_stumps: 10
multiview_cbound_boosting:
  n_stumps: 10