# The base configuration of the benchmark
Base :
  log: True
  name: ["metrics"]
  label: "_"
  type: ".hdf5"
  views:
  pathf: "/home/baptiste/Documents/Datasets/Generated/metrics_dset/"
  nice: 0
  random_state: 42
  nb_cores: 1
  full: True
  debug: True
  add_noise: False
  noise_std: 0.0
  res_dir: "../results/"

# All the classification-realted configuration options
Classification:
  multiclass_method: "oneVersusOne"
  split: 0.5
  nb_folds: 5
  nb_class: 2
  classes:
  type: ["multiview"]
  algos_monoview: ["random_forest"]
  algos_multiview: ["mucombo"]
  stats_iter: 1
  metrics: ["accuracy_score", "f1_score"]
  metric_princ: "f1_score"
  hps_type: "randomized_search"
  hps_iter: 1